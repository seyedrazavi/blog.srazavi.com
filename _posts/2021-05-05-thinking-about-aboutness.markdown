---
title: Thinking about Aboutness
date: 2021-05-05 12:39:00 Z
categories: [essays, journal]
tags:
- Philosophy
- Intentionality
comments: true
lang: en_GB
---

There are some questions that if you can't let go of, might push you towards philosophy. Questions like: Why is there something rather than nothing? What would justice in society look like? 

There are other question that arise with a bit of deeper thought when you're already engaged in topics with a philosophical bent. Questions such as: What is the difference between knowing something and just having the right opinion about it? Why does some matter have consciousness? 

Then there are questions that are obscure enough that if you're asking them, you're already deep in the debates of philosophy. These questions are easily distinguished from the former interesting philosophical questions. When you try to explain them to someone not familiar with the literature around the issue they give you a blank stare. You are sometimes met with incredulity that it is an issue worth worrying about at all. Most people give up on the big questions as unanswerable ("we'll never know why there is something rather than nothing"). But these third type of philosophical questions seem to most not even worth answering. 

Alas, for me, the question that interests me is one of those latter sorts. "Interest" is selling it a bit short. The fact is I've spent the last five years or so thinking about it in some variation. The question can be put very simply (but perhaps not very informatively): How is it that some things are *about* other things? Or more specifically, how is it that some of our mental states are about things in the world? 

I think about what I'm going to do today. I think where I left my cup of coffee. I wonder how my children are doing at nursery. In each case, I'm engaged in some activity where my mind is thinking about something else. When I see a book on my desk or a car on the road, my mind has an image about something out there in the world. When I hear the sound of a car backfiring or smell a soup in the kitchen, I am perceiving some *thing*. 

Out of these simple cases arises many puzzles. And I think philosophy is very appealing to people who like solving puzzles (of a certain sort). One puzzle is why do mental states have this characteristic when most physical stuff in the universe does not? Most things are just for themselves. They are not about other things. A rock is a rock. A tree is not about anything else. The sea does not point to something else for what it is.

Now, of course, there are things other than minds that are about other things. The words on this screen. The painting on the wall. The book on the shelf. The sound emanating from the radio. The words of our languages. The code of a computer program. What all these have in common though is that they were created by us. We minded animals whose thoughts imbued these objects with their aboutness. And whose minds are needed to give them aboutness at all. Whatever a book without a possible reader is about is lost until some mind can decipher the symbols on the page. To make them mean something again. We might say that all these objects have a derived kind of aboutness. The original aboutness comes from human minds. Or at least minds similar enough to their crafters who can restore the *about* relationship between the object and whatever it points at.

Other puzzles abound around aboutness if you think long enough on it. But I feel at this point a need to justify my thinking about it at all. I did not start out in philosophy with this particular mind worm. I got into this field because I wanted to answer a different question altogether. That question was: Will we ever build a thinking machine? 

Now my naive opinion back then was that, of course we will! I had studied Artificial Intelligence (AI) some twenty-years ago. We were at the beginning of a boom of AI technologies being deployed on tasks that twenty-years ago we were told was too hard. That they may not be soluble. 

Natural language translation in particular stood out because I had studied a lot of Chomsky in the late 1990s. Of course, other more famous milestones in game logic caught the public imagination as well. It seemed all the barriers towards building large scale artificial neural networks had gone. The availability of cheap utility computing on something akin to an electrical grid made new things possible. Major AI conferences and funding all pointed to a boom. Whilst I was not so naive to think we were around the corner from a genuine thinking machine, I did not see any reason against it happening one day.

Which was why when I encountered philosophers who were sceptical I scoffed at them. It did not seem to me these writers had much of a clue about where the state of the art was actually at. Many of their arguments stemmed from computation as it was in the 1960s and 1970s. Some cited Chomsky who I believed had been roundly shown to be wrong. The rest relied on esoteric metaphysical arguments from thinkers such as Heidegger whose reputations as obscure was all I had to go on. But more importantly, it all seemed like soothsaying to me. How could a philosophical argument rule out what was possible in actuality? Let the philosophers write their books. The engineers would build it.

This resistance to having your ideas challenged is a common factor in studying philosophy. It takes many forms. In my first year of undergraduate study, I witnessed it in major flare ups of heated discussions. The dividing lines are probably fairly predictable. Staunch atheists making the argument that belief in God was illogical. As the heat rose, illogical became an indictment of stupidity and immorality. Similar debates arose in ethics, political philosophy and so on. I managed to mostly stay away from these debates. I had walked some of these paths before (on both sides of the street) and could not see any resolution on questions of values. I focused my attention on problems about the mind. 

Everything other than mind, ancient philosophy, epistemology and metaphysics was a waste of my time. I settled on my path to answering the question that interested me ("Is it possible to build a thinking machine?"). I found two criteria that philosophers believed distinguished the mind from other things in the world.

The first was that minds have consciousness. Exactly what that is is harder to pin down. We all know it because we all have it. Perhaps, consciousness consists of a unified set of phenomenal experiences. There is a certain feel or what-it-is-like to what we experience in our minds. A distinctive quality about what we see, smell, taste or even when we think about things. These experiences all connect with each other into a whole. 

The second criteria is that minds have states that are about things. In philosopher jargon, they have *intentionality*.

As I thought about these two criteria, it seemed to me less and less clear the first was necessary for thinking. I do not want to rule it out. Maybe, as some philosophers suggest, phenomenal experience is simply a byproduct of thinking. There is something it is like to feel when thinking about something else. A qualitative aspect that arises from the thinking process. Or perhaps, to really do the kind of thinking we do, you need consciousness. 

Or perhaps, consciousness is a peculiar evolved ability of minded animals. Something that made sense for us to have but is not necessary for thinking as such. In other words, it seemed to me at least, that presuming a thinking machine needs to be conscious was to presume too much. 

Yet, I could not see how one could think without being able to think *about* things. If thoughts were not about something, then they would be empty and pointless. Sometimes thoughts would point outside of the thinker like the ball being kicked or the cup being lifted. Sometimes they would be internal. Thoughts about thoughts or imagined scenarios or abstract objects like mathematical symbols. Regardless, without aboutness it seemed to me thinking, or cognition more generally, could not get off the ground.

So, I settled on my problem and like any good philosophical problem, the more I thought about it, the harder it got. Yet, this has not been to my detriment. Because the process has been enriching and fascinating. 

It is a topic with a rich literature that divides philosophers in the 20th Century across two traditions. This divide is partly cultural norms in communication but also baked in assumptions about what kind of job is worth doing. It is of little interest to anybody outside of philosophy that such a divide exists. Yet, for better or worse, it seems universities in the UK are divided between these two camps. Rarely do the two traditions talk in terms they both can understand. This is particularly evident in my chosen problem domain of intentionality. 

One tradition is aligned with the natural and special sciences. The other is more anthropological and is more likely to draw from literature and earlier works of philosophy. Due to happenstance and temperament, I work in the tradition that aligns closely to the sciences. Yet, I spend a fair bit of time digging into the other tradition for my own understanding. It has coloured my overall approach. 

For ultimately, the quest I find myself on is not just to find out whether building a thinking machine is possible. But also, what is it that makes us uniquely human? I do not expect to answer such a question. I just can't help but ask it.